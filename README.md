# Hey, I'm Dan ğŸ‘‹

I'm an **Imaging Physicist and Data Scientist** working where **medical imaging and machine learning** meet.

My background in MRI/CT physics gives me a strong understanding of how images are formed, what can distort them, and how radiologists interpret subtle patterns. I use that foundation to build **models that are interpretable, stable, and clinically meaningful** â€” not just accurate on paper.

Iâ€™m interested in improving **radiology workflow efficiency, triage, and decision support**, especially in settings where time and clarity matter.

---

### ğŸ§  What I Work On

- Medical image modeling (MRI, CT, X-ray)
- Deep learning workflows and transfer learning (PyTorch)
- Model interpretability (Grad-CAM, feature importance)
- Quality control and dataset preparation for imaging pipelines
- Bridging **clinical image reasoning** with **data-driven inference**

---

### ğŸ—ï¸ Highlighted Project

| Project | Description | Tech |
|--------|-------------|------|
| **Brain MRI Tumor Classifier** | ResNet18 classifier for T1 post-contrast MRI slices with **Grad-CAM heatmaps** to show what regions influence decisions. Designed as a workflow triage concept, not diagnostic automation. | PyTorch, Torchvision, Matplotlib, OpenCV |

**Repo:** https://github.com/dsoliman2/brain-mri-tumor-classifier

---



### ğŸ§° Tools & Skills

**Languages:** Python (core), SQL, R, MATLAB  
**Modeling:** PyTorch, sklearn, transfer learning, Grad-CAM  
**Imaging:** MRI/CT physics, DICOM workflows, reconstruction artifacts, QC  
**Workflows:** PyCharm, Jupyter, Git, Kaggle

---

### ğŸ“ˆ Currently Exploring

- Data augmentation strategies for MRI generalization  
- Streamlit UI for interactive model evaluation  
- Tabular modeling + feature engineering for credit risk datasets  
- How interpretability can improve trust and adoption in clinical AI

---

### ğŸ“« Letâ€™s Connect

Always open to conversations about imaging, data science, clinical AI research, or interesting side ideas.



